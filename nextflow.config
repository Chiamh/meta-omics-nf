/*
========================================================================================
    meta-omics-nf Nextflow config file
========================================================================================
 	Adapted from the nf-core Nextflow base config file   

	A 'blank slate' config file, appropriate for general use on most high performance
    compute environments. Assumes that all software is installed and available on
    the PATH. Runs in `local` mode - all jobs will be run on the logged in environment.
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs
params {
	
	pipelineVersion					= '1.0'
	help 						= false
	
	// Input options
    	rna_reads					= null
    	dna_reads					= null
		rna_list					= null //if null, will recursively search rna_reads folder for *fastq.gz/*fq.gz/*fq/*fastq files
		dna_list					= null //if null, will recursively search dna_reads folder for *fastq.gz/*fq.gz/*fq/*fastq files
	decont_off					= false
	dedupe 						= true
	remove_rRNA					= true
	profilers_off					= false
	panalign_off					= false
	diamond_off					= false
	annotate_off					= false
	process_rna 					= true
	process_dna					= true
	rm_spikes					= true
	
	//Pipeline output options
	outdir              				= './pipeline_results'
	tracedir            				= "${params.outdir}/pipeline_info"
	
	//BWA References
	bwaidx_path					= null
	bwaidx						= null

        //Human Pangenome References
        human_pangenome_path                            = null

    	//STAR index
    	star_index                  			= null
	
	//rRNA removal
	ribokmers					= null
	
	//Read de-duplication for RNA seq
	dedupe						= true
	
	//Kraken2 and Bracken
	kraken2db					= null //path to folder containing kraken2 and bracken dbs
	readlength					= 150
	
	// Bowtie2 pangenome alignment
	pangenome_path 					= null //path to folder containing bowtie2 index files
	pangenome					= null //pangenome bowtie2 index name
	
	// Diamond translated search
	dmnddb 						= null //path to folder containing the diamond databases e.g. Uniref90 diamond db
        dmndfai                                         = null

	// Files for functional annotation
	spike_in_path					= null //path to file denoting genera/species to remove from metagenomes before functional profiling, because they are spike-ins
	eggnog_db					= null //path to folder containing the eggnog database
	eggnog_OG_annots				= null //path to a pre-built e5.og_annotations.tsv file, downloaded from http://eggnog5.embl.de/download/eggnog_5.0, sorted by EGGNOG ID
	uniref90_fasta					= null //path to fasta file containing amino acid sequences from Uniref90
	uniref90_GO					= null //path to two column .tsv file derived from https://ftp.uniprot.org/pub/databases/uniprot/knowledgebase/idmapping/idmapping_selected.tab.gz
	pangenome_annots				= null //path to pre-computed eggnog annotations for pangenome
	
	// AWS parameters
	awsregion 					= false
	awsqueue					= false
	
	// Max resource options
    // Defaults only, can be overwritten
    max_memory                 	= '200.GB'
    max_cpus                   	= 40
    max_time                   	= '240.h'
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

profiles {
   docker {
        docker.enabled         = true
        docker.userEmulation   = true
	docker.runOptions = "--memory-swap '-1'"
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
	   
	includeConfig 'conf/docker.config'
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
		
	includeConfig 'conf/singularity.config'
    }
    slurm {
	includeConfig 'conf/slurm.config'
    }
    sge {
	includeConfig 'conf/sge.config'
    }
    awsbatch {
	includeConfig 'conf/awsbatch.config'
    }
    test {
	includeConfig 'conf/test.config'
    }
    test_charon{
        includeConfig 'conf/test_charon.config'
    }
}


// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

// Nextflow log options
def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.svg"
}


manifest {
    name            = 'Chiamh/meta-omics-nf'
    author          = 'Minghao Chia'
    homePage        = 'https://github.com/Chiamh/meta-omics-nf'
    description     = 'Nextflow meta-omics analysis pipeline.'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=21.04.0'
    version         = '1.0'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
